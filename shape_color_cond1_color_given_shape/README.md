# Conditional Model: P(color | shape) Ã— P(shape)

This project implements the **conditional generative model** for colored shapes based on the compositional generative modeling paper: _"A Single Model is Not All You Need"_.

## ğŸ“Œ Goal
Learn to color grayscale shapes using a model that approximates:

```
P(shape, color) = P(color | shape) Ã— P(shape)
```

- **P(shape)** is implicitly learned by the grayscale shape VAE.
- **P(color | shape)** is learned by a CNN that maps grayscale shapes to RGB versions.

---

## ğŸ“‚ Folder Structure
```
.
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_color_mapper.py         # Training script
â”‚   â””â”€â”€ view_results.ipynb           # Visualize input/output pairs
â”œâ”€â”€ color_mapper.py                  # U-Net-like model (1-channel â†’ 3-channel)
â”œâ”€â”€ color_dataset.py                 # Dataset for grayscale input + RGB targets
â”œâ”€â”€ samples/cond1/                   # Saved outputs every N epochs
â””â”€â”€ models/                          # Trained model weights
```

---

## ğŸ§  Model Architecture
### `ColorMapper`
- Input: 1Ã—64Ã—64 grayscale image
- Output: 3Ã—64Ã—64 color prediction
- Structure: 2 conv layers â†’ middle conv â†’ 2 transposed conv layers

### Loss Function
```
loss = MSE(pred, target) + 
       edge_weight Ã— EdgeLoss(pred, target)
```

- `EdgeLoss` encourages the predicted color transitions to align with shape edges.

---

## ğŸš€ Training
```bash
python scripts/train_color_mapper.py
```
Outputs will be saved to:
```
samples/cond1/output_color_epochXX.png
samples/cond1/input_gray_epochXX.png
```

---

## ğŸ” Evaluation
Use `view_results.ipynb` to compare grayscale inputs and predicted color outputs.

Unseen combinations such as **green triangle** or **blue square** indicate generalization ability.

---

## ğŸ“ˆ Result Highlights
- Accurate shape-to-color prediction from grayscale inputs
- Sharp color boundaries
- Generalization to unseen combinations in some cases

---

## ğŸ”„ Next Steps
Try training alternate factorizations:
- `P(color) Ã— P(shape | color)`
- Joint `P(shape, color)` as a single VAE

Then compare all four models under a fixed training budget.

---

## ğŸ“¬ Author
Abhiram Varma Nandimandalam  
M.S. Data Science @ University of Arizona  
[GitHub](https://github.com/isjustabhi)
